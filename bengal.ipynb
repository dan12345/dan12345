{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeLuyPmKqL5G8sbaGYJUAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dan12345/dan12345/blob/main/bengal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install wordhoard\n",
        "!pip3 install nltk\n",
        "import nltk\n",
        "import pickle\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
        "from wordhoard import Homophones\n",
        "\n",
        "\n",
        "class word_stats:\n",
        "  self.occurances = []\n",
        "  self.count = 0 \n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "\n",
        "class doc_summary:\n",
        "  \n",
        "  self.word_mapping = {}\n",
        "  \n",
        "  def __init__(self,texts):\n",
        "    word_mapping = {}\n",
        "    for text, i in enumrate(texts):\n",
        "      sentences = sent_tokenize(text)\n",
        "      for sen, j in enumerate(sentences):\n",
        "      \n",
        "\n",
        "def create_summarized(texts):\n",
        "  \n",
        "    \"\n",
        "\n",
        "def find_wsd(text):\n",
        "  print(\"######################################\")\n",
        "  print(\"WSD analysis\")\n",
        "\n",
        "  print(\"\\n######################################\")\n",
        "\n",
        "\n",
        "def find_homonyms(text):\n",
        "  ''' \n",
        "  print out the hononyms found in the text, \n",
        "  together with the number of occurences of each word and the sentences where they occured.\n",
        "  Relying at the moment on a random 3'rd party library, and code is ineffecient. Don't tell anyone. \n",
        "  '''\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  words = tokenizer.tokenize(text)\n",
        "  sentences = sent_tokenize(text)\n",
        "  homonyms = set()\n",
        "  for i in range(0, len(words)):\n",
        "    homophone = Homophones(words[i])\n",
        "    homophone_results = homophone.find_homophones()\n",
        "    if type(homophone_results) == list: # result is list with \"words[i] is homophone of X is there is\", or string of none found else\n",
        "      for hom in [word_tokenize(l)[-1] for l in homophone_results]:\n",
        "        if hom in words:\n",
        "          tup = (words[i], hom) if words[i] < hom else (hom, words[i])\n",
        "          homonyms.add(tup)\n",
        "  \n",
        "  \n",
        "  print(\"\\n######################################\")\n",
        "  print(\"Homonym analysis:\")\n",
        "  if len(homonyms) == 0:\n",
        "    print(\"Didn't find any homonyms in the text\")\n",
        "  count = 0 \n",
        "  for hom in homonyms:\n",
        "    print(\"\\nHomonym number %s: %s\\n\" % (count, hom))\n",
        "    count+=1\n",
        "    count0 = 0\n",
        "    count1 = 0  \n",
        "    print(\"sentences that homonym appears in:\")\n",
        "    sen_to_print = []\n",
        "    for sen in sentences:\n",
        "      words = tokenizer.tokenize(sen)\n",
        "      count0 = count0+1 if hom[0] in words else count0\n",
        "      count1 = count1+1 if hom[0] in words else count1\n",
        "      if hom[0] in words or hom[1] in words:  \n",
        "        print('\"%s\"' % sen)\n",
        "    print(\"%s appears %s times, %s appears %s times\"% (hom[0], count0, hom[1], count1))\n",
        "    print(\"####\")    \n",
        "  print(\"end of homonym analysis\")  \n",
        "  print(\"######################################\")\n",
        "\n",
        "def run_analysis(text):\n",
        "  find_homonyms(text.lower())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKOW4uAFP1Ky",
        "outputId": "d8032729-ec8b-4d5f-a2c4-a1fbee74b901"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordhoard in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (2022.12.7)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (4.9.2)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (2.3.2.post1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (4.11.1)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (2.28.2)\n",
            "Requirement already satisfied: urllib3==1.25.11 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (1.25.11)\n",
            "Requirement already satisfied: backoff>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (2.2.1)\n",
            "Requirement already satisfied: deckar01-ratelimit>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (3.0.2)\n",
            "Requirement already satisfied: deepl>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (1.12.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wordhoard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.27.1->wordhoard) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Dear sir. i saw a deer. i remember John Deare. He loves to bare witness to a bear eating honey \"\n",
        "run_analysis(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l5fd2Pl7Jqc",
        "outputId": "75648436-1195-484f-c39c-b1cdea367ffa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################\n",
            "Homonym analysis:\n",
            "\n",
            "Homonym number 0: ('bare', 'bear')\n",
            "\n",
            "sentences that homonym appears in:\n",
            "\"he loves to bare witness to a bear eating honey\"\n",
            "bare appears 1 times, bear appears 1 times\n",
            "####\n",
            "\n",
            "Homonym number 1: ('dear', 'deer')\n",
            "\n",
            "sentences that homonym appears in:\n",
            "\"dear sir.\"\n",
            "\"i saw a deer.\"\n",
            "dear appears 1 times, deer appears 1 times\n",
            "####\n",
            "end of homonym analysis\n",
            "######################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zLR9DK67VLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}